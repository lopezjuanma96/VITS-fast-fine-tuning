{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGi2mFHmzN1k"
      },
      "outputs": [],
      "source": [
        "# 查看GPU配置\n",
        "# Check GPU configuration\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1qEtyyuDbGz"
      },
      "source": [
        "#这个笔记本由于pipeline更新已经不能使用了，请使用[新版本](https://colab.research.google.com/drive/1pn1xnFfdLK63gVXDwV4zCXfVeo8c-I-0?usp=sharing)\n",
        "#同时请参照新版本的[使用说明](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_ZH.md)\n",
        "#不便之处敬请谅解😥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAmtLe3_z1Ea"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown #STEP 1 (3 min)\n",
        "#@markdown ##复制代码库并安装运行环境\n",
        "#@markdown ##Clone repository & Build environment\n",
        "! git clone https://github.com/lopezjuanma96/VITS-fast-fine-tuning.git\n",
        "%cd VITS-fast-fine-tuning\n",
        "!pip install -r requirements.txt\n",
        "# build monotonic align\n",
        "%cd monotonic_align/\n",
        "!mkdir monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "%cd ..\n",
        "!mkdir pretrained_models\n",
        "%cd pretrained_models\n",
        "# download pretrained discriminator checkpoint\n",
        "!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth\n",
        "#!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth\n",
        "!wget https://huggingface.co/lopezjm96/spanishVITS/resolve/main/G_spanish.pth -O G_trilingual.pth\n",
        "%cd ..\n",
        "# download data for fine-tuning\n",
        "!wget https://huggingface.co/datasets/lopezjm96/spanish_voices/resolve/main/spanish_voices.zip\n",
        "!unzip spanish_voices.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6bj4kklj_jZ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown #STEP 2 (5~10 min)\n",
        "#@markdown 如果你不需要变声器功能，可以跳过这步。  \n",
        "\n",
        "#@markdown 运行该代码块之后会出现一个UI，在这里阅读短句从而录入你的声音。  \n",
        "#@markdown 录入20句以达到最低限度的效果。录入40句以上可以保证最佳效果。  \n",
        "\n",
        "#@markdown (No. 0~44 为中文句子)  \n",
        "\n",
        "#@markdown If you don't need the function of converting your voice to other characters', you can skip this block \n",
        "\n",
        "#@markdown Running this code block will present a UI below. \n",
        "#@markdown Read the text to teach the model your voice! \n",
        "#@markdown (20 at least, for better conversion quality, 40+ is suggested)  \n",
        "\n",
        "#@markdown (No. 45~92 are English sentences)\n",
        "%run user_voice_collect.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtRRxOLkkUJ0"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown #STEP 2.5\n",
        "#@markdown ### 可选：使用Demucs对录音进行去噪以提高转换质量 （花费约8秒一句）\n",
        "#@markdown ### Optional: Denoise recorded audio for better voice conversion quality\n",
        "#@markdown ### (takes about 8 seconds per .wav file on colab free GPU)\n",
        "!python demucs_denoise.py --denoise_user True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qly_xCdmQPr7"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown #STEP 3\n",
        "#@markdown 如果你不需要添加自己的角色，可以跳过这步。  \n",
        "\n",
        "#@markdown 运行该代码块会出现一个文件上传的入口，\n",
        "#@markdown 按照[README](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_ZH.md)中描述的格式上传单个zip文件。  \n",
        "\n",
        "#@markdown 注意只能上传zip文件，上传其它压缩文件格式(.rar, .7z等)是解不出来的  \n",
        "\n",
        "#@markdown Whisper在自动标注时出现错别字是几乎不影响标注质量的，\n",
        "#@markdown 因为最后转化成音素的时候都差不多。\n",
        "\n",
        "#@markdown If you don't want to add your characters, you can skip this block.  \n",
        "\n",
        "#@markdown Running this codeblock will prompt you to upload a file. \n",
        "#@markdown You should upload a zip file, whose file structure should \n",
        "#@markdown be consistent as described in the [README](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_EN.md) page.\n",
        "%run voice_upload.py\n",
        "!unzip ./custom_character_voice/custom_character_voice.zip -d ./custom_character_voice/\n",
        "!python whisper_transcribe.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb6MuC5DvgfZ"
      },
      "outputs": [],
      "source": [
        "%run preprocess.py\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"./OUTPUT_MODEL\"\n",
        "#@markdown #STEP 4 (>=20 min)\n",
        "#@markdown 开始微调模型，在20轮训练后会自动结束。\n",
        "#@markdown 训练时长取决于你录入/上传的音频总数。\n",
        "\n",
        "#@markdown 一般建议设置为10~20epochs，多了可能会过拟合。  \n",
        "\n",
        "#@markdown 你也可以在Tensorboard中预览合成效果，若效果满意可提前停止。\n",
        "\n",
        "#@markdown Model fine-tuning ends after 20 epochs. \n",
        "#@markdown Total time cost depends on the number of voices you recorded/uploaded.   \n",
        "\n",
        "#@markdown 10~20 epochs is recommended because too much training may result in overfitting.\n",
        "\n",
        "#@markdown You can also preview synthezied audio in Tensorboard, it's OK to shut down training manually if you find the quality is satisfying.\n",
        "# Model checkpoints are automatically saved to ./OUTPUT_MODEL/G_latest.pth\n",
        "Maximum_epochs = \"20\" #@param [10, 20, 30]\n",
        "!python finetune_speaker.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuvViuwE9k_W"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown ### 微调完成后，在这里尝试效果。\n",
        "#@markdown ### Try out conversion quality here after fine-tuning is finished.\n",
        "!cp ./configs/modified_finetune_speaker.json ./finetune_speaker.json\n",
        "%run VC_inference.py --model_dir ./OUTPUT_MODEL/G_latest.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL8TF605yrKT"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#@markdown ### 下载微调好的模型和config文件以便本地部署。\n",
        "#@markdown ### Download fine-tuned model & config file for local inference.\n",
        "!cp ./configs/modified_finetune_speaker.json ./finetune_speaker.json\n",
        "%run download_model.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
